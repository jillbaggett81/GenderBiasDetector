{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /Users/leahkuperman/opt/anaconda3/lib/python3.8/site-packages (4.5.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install lxml\n",
    "#import all tools for project\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining the Frequency of Gendered Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\n",
    "\n",
    "Dr. Mattei, Tulane University. SimpleText Notebook. 2020. \n",
    "Bo Pang and Lillian Lee, A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts, Proceedings of ACL 2004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Review</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Very good</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Exelent he really care about you, he is very p...</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Dr. A-Rahim was very knowledgeable about my lo...</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Horrible physician treats you like a kid. Pts ...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Dr Aaberg has been a very good dr for my husba...</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8890</th>\n",
       "      <td>8890</td>\n",
       "      <td>Very helpful and sincere about my pain needs! ...</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8891</th>\n",
       "      <td>8891</td>\n",
       "      <td>Several of my children see Dr. Zach, she is a ...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8892</th>\n",
       "      <td>8892</td>\n",
       "      <td>Amazing Pediatric Neurologist stays up to date...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8893</th>\n",
       "      <td>8893</td>\n",
       "      <td>Dr. Zach has been a Godsend for our daughter! ...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8894</th>\n",
       "      <td>8894</td>\n",
       "      <td>Very friendly doctor and not pushy. Makes you ...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8895 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                             Review  Gender\n",
       "0              0                                          Very good    Male\n",
       "1              1  Exelent he really care about you, he is very p...    Male\n",
       "2              2  Dr. A-Rahim was very knowledgeable about my lo...    Male\n",
       "3              3  Horrible physician treats you like a kid. Pts ...  Female\n",
       "4              4  Dr Aaberg has been a very good dr for my husba...    Male\n",
       "...          ...                                                ...     ...\n",
       "8890        8890  Very helpful and sincere about my pain needs! ...    Male\n",
       "8891        8891  Several of my children see Dr. Zach, she is a ...  Female\n",
       "8892        8892  Amazing Pediatric Neurologist stays up to date...  Female\n",
       "8893        8893  Dr. Zach has been a Godsend for our daughter! ...  Female\n",
       "8894        8894  Very friendly doctor and not pushy. Makes you ...  Female\n",
       "\n",
       "[8895 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import CSV containing mass amount of scraped reviews for analysis\n",
    "reviewsByGender = pd.read_csv(\"./revs_gendered.csv\")\n",
    "reviewsByGender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8895x7365 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 322903 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the whole thing...\n",
    "import sklearn\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Vectorize and play with token sizes...\n",
    "vec = TfidfVectorizer(min_df = 2, \n",
    "                      max_df = 0.98, \n",
    "                      ngram_range=(1,1)) # play with min_df and max_df\n",
    "\n",
    "reviews = reviewsByGender['Review']\n",
    "\n",
    "# transform this into a sparse vector!\n",
    "vec.fit(reviews)\n",
    "tf_idf_sparse = vec.transform(reviews)\n",
    "tf_idf_sparse\n",
    "\n",
    "#only 222 unique words due to min_df 0.03 --> change to 2, maybe change to 5 (could get meaningless words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "revs = dict(zip(reviewsByGender.Review, reviewsByGender.Gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of cleaned, stemmed adjectives, for later analysis. \n",
    "vect = CountVectorizer()\n",
    "vect.fit(revs)\n",
    "words = vect.get_feature_names()\n",
    "\n",
    "adjectives = []\n",
    "stop_words = list(set(stopwords.words('english')))\n",
    "\n",
    "# remove stopwords \n",
    "stopped = [w for w in words if not w in stop_words]\n",
    "    \n",
    "# parts of speech tagging for each word \n",
    "pos = nltk.pos_tag(stopped)\n",
    "\n",
    "# make a list of  all adjectives identified by the allowed word types list above\n",
    "for w in pos:\n",
    "    if w[1][0] == 'J':\n",
    "        adjectives.append(w[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7004)\t0.5113918885739566\n",
      "  (0, 2832)\t0.8593476225025365\n"
     ]
    }
   ],
   "source": [
    "print(tf_idf_sparse[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now use this to classify the reviews!! but we need to test/train split again.\n",
    "\n",
    "# Split..\n",
    "X_train, X_test, y_train, y_test = train_test_split(tf_idf_sparse, \n",
    "                                                    reviewsByGender['Gender'], \n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression(max_iter=100000, class_weight='balanced') \n",
    "model = logisticRegr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Female', 'Male'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17571364])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.coef_[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe with the words, coefficients, and classes...\n",
    "recs = []\n",
    "\n",
    "for w,i in vec.vocabulary_.items():\n",
    "    recs.append([str(w)] + list(logisticRegr.coef_[:,i]))\n",
    "# If we only have one class then we only get weight..\n",
    "# df_weights = pd.DataFrame(tripples, columns=['word']+list(logisticRegr.classes_))\n",
    "df_weights = pd.DataFrame(recs, columns=['word', 'weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>he</td>\n",
       "      <td>13.331486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>his</td>\n",
       "      <td>8.833455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>him</td>\n",
       "      <td>7.214020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>surgery</td>\n",
       "      <td>3.497624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>man</td>\n",
       "      <td>1.771411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>outstanding</td>\n",
       "      <td>1.528613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>informative</td>\n",
       "      <td>1.421560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>mother</td>\n",
       "      <td>1.376369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>knee</td>\n",
       "      <td>1.329925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>was</td>\n",
       "      <td>1.309487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>surgeon</td>\n",
       "      <td>1.247323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7301</th>\n",
       "      <td>yacoub</td>\n",
       "      <td>1.201705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>staff</td>\n",
       "      <td>1.185640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>pain</td>\n",
       "      <td>1.153861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>arrogant</td>\n",
       "      <td>1.117337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good</td>\n",
       "      <td>1.102414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>recovery</td>\n",
       "      <td>1.077212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4753</th>\n",
       "      <td>faber</td>\n",
       "      <td>1.055406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>replacement</td>\n",
       "      <td>1.032310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>would</td>\n",
       "      <td>1.003537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7264</th>\n",
       "      <td>wacks</td>\n",
       "      <td>0.947087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>thanks</td>\n",
       "      <td>0.938076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791</th>\n",
       "      <td>cardiologist</td>\n",
       "      <td>0.901552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>guy</td>\n",
       "      <td>0.897284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>going</td>\n",
       "      <td>0.880122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word     weight\n",
       "3               he  13.331486\n",
       "85             his   8.833455\n",
       "84             him   7.214020\n",
       "328        surgery   3.497624\n",
       "920            man   1.771411\n",
       "86     outstanding   1.528613\n",
       "984    informative   1.421560\n",
       "1358        mother   1.376369\n",
       "546           knee   1.329925\n",
       "14             was   1.309487\n",
       "222        surgeon   1.247323\n",
       "7301        yacoub   1.201705\n",
       "87           staff   1.185640\n",
       "410           pain   1.153861\n",
       "1111      arrogant   1.117337\n",
       "1             good   1.102414\n",
       "540       recovery   1.077212\n",
       "4753         faber   1.055406\n",
       "1244   replacement   1.032310\n",
       "200          would   1.003537\n",
       "7264         wacks   0.947087\n",
       "12          thanks   0.938076\n",
       "2791  cardiologist   0.901552\n",
       "1219           guy   0.897284\n",
       "178          going   0.880122"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weights.sort_values('weight', ascending=False)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>outstanding</td>\n",
       "      <td>1.528613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>arrogant</td>\n",
       "      <td>1.117337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good</td>\n",
       "      <td>1.102414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4753</th>\n",
       "      <td>faber</td>\n",
       "      <td>1.055406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>great</td>\n",
       "      <td>0.849152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>kindness</td>\n",
       "      <td>0.815535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>fine</td>\n",
       "      <td>0.721397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>much</td>\n",
       "      <td>0.680306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>pa</td>\n",
       "      <td>0.649378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7156</th>\n",
       "      <td>udall</td>\n",
       "      <td>0.625234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>total</td>\n",
       "      <td>0.612242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4143</th>\n",
       "      <td>ambrosio</td>\n",
       "      <td>0.612037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>explain</td>\n",
       "      <td>0.608897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6911</th>\n",
       "      <td>rabady</td>\n",
       "      <td>0.596992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>willing</td>\n",
       "      <td>0.578309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>leg</td>\n",
       "      <td>0.568768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>usual</td>\n",
       "      <td>0.541507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>old</td>\n",
       "      <td>0.536070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>courteous</td>\n",
       "      <td>0.525404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>er</td>\n",
       "      <td>0.517237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>rudest</td>\n",
       "      <td>0.505465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>knowledgable</td>\n",
       "      <td>0.502381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>severe</td>\n",
       "      <td>0.491100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>direct</td>\n",
       "      <td>0.484803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>personal</td>\n",
       "      <td>0.484637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word    weight\n",
       "86     outstanding  1.528613\n",
       "1111      arrogant  1.117337\n",
       "1             good  1.102414\n",
       "4753         faber  1.055406\n",
       "21           great  0.849152\n",
       "2291      kindness  0.815535\n",
       "723           fine  0.721397\n",
       "110           much  0.680306\n",
       "1815            pa  0.649378\n",
       "7156         udall  0.625234\n",
       "1243         total  0.612242\n",
       "4143      ambrosio  0.612037\n",
       "112        explain  0.608897\n",
       "6911        rabady  0.596992\n",
       "250        willing  0.578309\n",
       "892            leg  0.568768\n",
       "1606         usual  0.541507\n",
       "587            old  0.536070\n",
       "249      courteous  0.525404\n",
       "38              er  0.517237\n",
       "3254        rudest  0.505465\n",
       "1488  knowledgable  0.502381\n",
       "264         severe  0.491100\n",
       "3010        direct  0.484803\n",
       "875       personal  0.484637"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print only adjectives\n",
    "#male adjectives\n",
    "maleAdjectives = df_weights[df_weights['word'].isin(adjectives)].sort_values('weight', ascending=False)[:25]\n",
    "maleAdjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>she</td>\n",
       "      <td>-13.941201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>her</td>\n",
       "      <td>-10.924884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4699</th>\n",
       "      <td>ma</td>\n",
       "      <td>-2.729389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4442</th>\n",
       "      <td>eady</td>\n",
       "      <td>-1.732895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>kabbash</td>\n",
       "      <td>-1.526565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6504</th>\n",
       "      <td>nabors</td>\n",
       "      <td>-1.484614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6708</th>\n",
       "      <td>pabolu</td>\n",
       "      <td>-1.468074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>unprofessional</td>\n",
       "      <td>-1.423117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>woman</td>\n",
       "      <td>-1.374594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7309</th>\n",
       "      <td>yablonski</td>\n",
       "      <td>-1.363092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>child</td>\n",
       "      <td>-1.238058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>prescription</td>\n",
       "      <td>-1.235365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>sweet</td>\n",
       "      <td>-1.180887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7007</th>\n",
       "      <td>saadai</td>\n",
       "      <td>-1.169989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7319</th>\n",
       "      <td>yacoob</td>\n",
       "      <td>-1.144465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>pregnancy</td>\n",
       "      <td>-1.133458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>appointments</td>\n",
       "      <td>-1.102387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>love</td>\n",
       "      <td>-1.100054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>today</td>\n",
       "      <td>-1.053321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>happy</td>\n",
       "      <td>-1.040171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>cancer</td>\n",
       "      <td>-1.026063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7290</th>\n",
       "      <td>xiao</td>\n",
       "      <td>-1.019756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6017</th>\n",
       "      <td>kotler</td>\n",
       "      <td>-1.000181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>specialist</td>\n",
       "      <td>-0.997463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5233</th>\n",
       "      <td>cheryl</td>\n",
       "      <td>-0.996548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word     weight\n",
       "44               she -13.941201\n",
       "396              her -10.924884\n",
       "4699              ma  -2.729389\n",
       "4442            eady  -1.732895\n",
       "5981         kabbash  -1.526565\n",
       "6504          nabors  -1.484614\n",
       "6708          pabolu  -1.468074\n",
       "303   unprofessional  -1.423117\n",
       "588            woman  -1.374594\n",
       "7309       yablonski  -1.363092\n",
       "331            child  -1.238058\n",
       "295     prescription  -1.235365\n",
       "1452           sweet  -1.180887\n",
       "7007          saadai  -1.169989\n",
       "7319          yacoob  -1.144465\n",
       "711        pregnancy  -1.133458\n",
       "836     appointments  -1.102387\n",
       "419             love  -1.100054\n",
       "797            today  -1.053321\n",
       "712            happy  -1.040171\n",
       "1462          cancer  -1.026063\n",
       "7290            xiao  -1.019756\n",
       "6017          kotler  -1.000181\n",
       "136       specialist  -0.997463\n",
       "5233          cheryl  -0.996548"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weights.sort_values('weight', ascending=True)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4442</th>\n",
       "      <td>eady</td>\n",
       "      <td>-1.732895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>unprofessional</td>\n",
       "      <td>-1.423117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>sweet</td>\n",
       "      <td>-1.180887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>happy</td>\n",
       "      <td>-1.040171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3512</th>\n",
       "      <td>cabalona</td>\n",
       "      <td>-0.951560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>knowledgeable</td>\n",
       "      <td>-0.942386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>wonderful</td>\n",
       "      <td>-0.875642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>ok</td>\n",
       "      <td>-0.772957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>annual</td>\n",
       "      <td>-0.756692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>perfect</td>\n",
       "      <td>-0.754531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633</th>\n",
       "      <td>pediatrician</td>\n",
       "      <td>-0.742959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>insightful</td>\n",
       "      <td>-0.736732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>lowest</td>\n",
       "      <td>-0.723254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125</th>\n",
       "      <td>angel</td>\n",
       "      <td>-0.694796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>several</td>\n",
       "      <td>-0.692631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>primary</td>\n",
       "      <td>-0.692162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2965</th>\n",
       "      <td>lovely</td>\n",
       "      <td>-0.684240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>spent</td>\n",
       "      <td>-0.662398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>convenient</td>\n",
       "      <td>-0.618489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>cancerous</td>\n",
       "      <td>-0.614929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>difficult</td>\n",
       "      <td>-0.597908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>brilliant</td>\n",
       "      <td>-0.597294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>leave</td>\n",
       "      <td>-0.583219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>dismissive</td>\n",
       "      <td>-0.548932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>front</td>\n",
       "      <td>-0.540202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word    weight\n",
       "4442            eady -1.732895\n",
       "303   unprofessional -1.423117\n",
       "1452           sweet -1.180887\n",
       "712            happy -1.040171\n",
       "3512        cabalona -0.951560\n",
       "15     knowledgeable -0.942386\n",
       "481        wonderful -0.875642\n",
       "999               ok -0.772957\n",
       "1314          annual -0.756692\n",
       "1533         perfect -0.754531\n",
       "2633    pediatrician -0.742959\n",
       "3128      insightful -0.736732\n",
       "2600          lowest -0.723254\n",
       "3125           angel -0.694796\n",
       "392          several -0.692631\n",
       "691          primary -0.692162\n",
       "2965          lovely -0.684240\n",
       "20             spent -0.662398\n",
       "864       convenient -0.618489\n",
       "3991       cancerous -0.614929\n",
       "273        difficult -0.597908\n",
       "221        brilliant -0.597294\n",
       "1336           leave -0.583219\n",
       "304       dismissive -0.548932\n",
       "858            front -0.540202"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#female adjectives\n",
    "femaleAdjectives = df_weights[df_weights['word'].isin(adjectives)].sort_values('weight', ascending=True)[:25]\n",
    "#maybe take out adjective specification\n",
    "#vocabulary being pruned down too aggressively\n",
    "femaleAdjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for most commonly found female adjectives:\n",
      "Agentic:  0\n",
      "Communal:  0\n",
      "Socio-communal:  0\n",
      "\n",
      "Results for most commonly found male adjectives:\n",
      "Agentic:  0\n",
      "Communal:  0\n",
      "Socio-communal:  0\n"
     ]
    }
   ],
   "source": [
    "#verify results\n",
    "agentic_terms = ['assertive','confident','aggressive','ambitious','dominan','forceful','independent','daring','outspoken','intellectua','earn','gain','know','insight','think']\n",
    "communal_terms = ['sympathetic','kind','help','affection','sensitive','nurtur','agreeab','tactful','interpersonal','warm','car','tactful']\n",
    "socio_communal = ['husband','wife','kid','babies','brother','child','colleague','family']\n",
    "\n",
    "print('Results for most commonly found female adjectives:')\n",
    "print('Agentic: ', femaleAdjectives['word'].isin(agentic_terms).sum())\n",
    "print('Communal: ', femaleAdjectives['word'].isin(communal_terms).sum())\n",
    "print('Socio-communal: ', femaleAdjectives['word'].isin(socio_communal).sum())\n",
    "print('')\n",
    "print('Results for most commonly found male adjectives:')\n",
    "print('Agentic: ', maleAdjectives['word'].isin(agentic_terms).sum())\n",
    "print('Communal: ', maleAdjectives['word'].isin(communal_terms).sum())\n",
    "print('Socio-communal: ', maleAdjectives['word'].isin(socio_communal).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can use medical reviews to run with recommnedation letter reviews to predict which is which, then throw out \n",
    "#heavily medical terms\n",
    "\n",
    "# recommendation system\n",
    "# maybe seek out positive words that don't distinguish between male and female\n",
    "# 4-class problem rather than two-class problem: take in star data and add pos/neg dimension to the data\n",
    "# word vector stuff from NLP class: use language models and figure out how often it appears in male context vs\n",
    "# female context. Ex: look at similarities between words: compare \"leadership\" to \"man/men\" \n",
    "\n",
    "#doubt raisers may not come out from this analysis: \"she may not be the best in her class...\"\n",
    "# subtle, hard to catch -> maybe the word \"not\"\n",
    "# append \"not\" to nearest adjective, negated adjectives might indicate doubt raisers\n",
    "# hedging terms to weaken a statement (weasel words): refusing to take a stand/hesitant\n",
    "# \"somewhat\", \"mostly\"\n",
    "\n",
    "# how to rephrase it: female-correlated to neutral, remove hedging terms\n",
    "# take an education based approach: \"this can be conveyed as ___. If that is not your intention, consider ___\"\n",
    "# crowdsourcing: emphasize anonymization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
