{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (4.5.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install lxml\n",
    "#import all tools for project\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining the Frequency of Gendered Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\n",
    "\n",
    "Dr. Mattei, Tulane University. SimpleText Notebook. 2020. \n",
    "Bo Pang and Lillian Lee, A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts, Proceedings of ACL 2004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Exelent he really care about you, he is very p...</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Dr. A-Rahim was very knowledgeable about my lo...</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Horrible physician treats you like a kid. Pts ...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dr Aaberg has been a very good dr for my husba...</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Dr. Aaberg has been treating my macular degene...</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8889</td>\n",
       "      <td>Very helpful and sincere about my pain needs! ...</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8890</td>\n",
       "      <td>Several of my children see Dr. Zach, she is a ...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8891</td>\n",
       "      <td>Amazing Pediatric Neurologist stays up to date...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8892</td>\n",
       "      <td>Dr. Zach has been a Godsend for our daughter! ...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8893</td>\n",
       "      <td>Very friendly doctor and not pushy. Makes you ...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8894 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  Gender\n",
       "0     Exelent he really care about you, he is very p...    Male\n",
       "1     Dr. A-Rahim was very knowledgeable about my lo...    Male\n",
       "2     Horrible physician treats you like a kid. Pts ...  Female\n",
       "3     Dr Aaberg has been a very good dr for my husba...    Male\n",
       "4     Dr. Aaberg has been treating my macular degene...    Male\n",
       "...                                                 ...     ...\n",
       "8889  Very helpful and sincere about my pain needs! ...    Male\n",
       "8890  Several of my children see Dr. Zach, she is a ...  Female\n",
       "8891  Amazing Pediatric Neurologist stays up to date...  Female\n",
       "8892  Dr. Zach has been a Godsend for our daughter! ...  Female\n",
       "8893  Very friendly doctor and not pushy. Makes you ...  Female\n",
       "\n",
       "[8894 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import CSV containing mass amount of scraped reviews for analysis\n",
    "reviewsByGender = pd.read_csv(\"./revs_gendered.csv\")\n",
    "reviewsByGender.dropna(inplace = True)\n",
    "reviewsByGender.columns = ['Review', 'Gender']\n",
    "reviewsByGender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8894x7365 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 322901 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the whole thing...\n",
    "import sklearn\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Vectorize and play with token sizes...\n",
    "vec = TfidfVectorizer(min_df = 2, \n",
    "                      max_df = 0.98, \n",
    "                      ngram_range=(1,1)) # play with min_df and max_df\n",
    "\n",
    "reviews = reviewsByGender['Review']\n",
    "\n",
    "# transform this into a sparse vector!\n",
    "vec.fit(reviews)\n",
    "tf_idf_sparse = vec.transform(reviews)\n",
    "tf_idf_sparse\n",
    "\n",
    "#only 222 unique words due to min_df 0.03 --> change to 2, maybe change to 5 (could get meaningless words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "revs = dict(zip(reviewsByGender.Review, reviewsByGender.Gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of cleaned, stemmed adjectives, for later analysis. \n",
    "vect = CountVectorizer()\n",
    "vect.fit(revs)\n",
    "words = vect.get_feature_names()\n",
    "\n",
    "adjectives = []\n",
    "stop_words = list(set(stopwords.words('english')))\n",
    "\n",
    "# remove stopwords \n",
    "stopped = [w for w in words if not w in stop_words]\n",
    "    \n",
    "# parts of speech tagging for each word \n",
    "pos = nltk.pos_tag(stopped)\n",
    "\n",
    "# make a list of  all adjectives identified by the allowed word types list above\n",
    "for w in pos:\n",
    "    if w[1][0] == 'J':\n",
    "        adjectives.append(w[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7326)\t0.18151009711676813\n",
      "  (0, 7004)\t0.14519230383170104\n",
      "  (0, 6487)\t0.3553485932395106\n",
      "  (0, 5284)\t0.2785536271904824\n",
      "  (0, 5073)\t0.23861251000309455\n",
      "  (0, 3489)\t0.12256067027657984\n",
      "  (0, 2968)\t0.26339587134769354\n",
      "  (0, 2375)\t0.6439667942787456\n",
      "  (0, 2052)\t0.10518473469832991\n",
      "  (0, 1396)\t0.2868414706993512\n",
      "  (0, 1126)\t0.20412772247184602\n",
      "  (0, 466)\t0.0871391073049557\n",
      "  (0, 192)\t0.20851297268798946\n"
     ]
    }
   ],
   "source": [
    "print(tf_idf_sparse[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now use this to classify the reviews!! but we need to test/train split again.\n",
    "\n",
    "# Split..\n",
    "X_train, X_test, y_train, y_test = train_test_split(tf_idf_sparse, \n",
    "                                                    reviewsByGender['Gender'], \n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurensussman/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression(max_iter=100000, class_weight='balanced') \n",
    "model = logisticRegr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Female', 'Male'], dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21094106])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.coef_[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe with the words, coefficients, and classes...\n",
    "recs = []\n",
    "\n",
    "for w,i in vec.vocabulary_.items():\n",
    "    recs.append([str(w)] + list(logisticRegr.coef_[:,i]))\n",
    "# If we only have one class then we only get weight..\n",
    "# df_weights = pd.DataFrame(tripples, columns=['word']+list(logisticRegr.classes_))\n",
    "df_weights = pd.DataFrame(recs, columns=['word', 'weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>he</td>\n",
       "      <td>13.413569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>his</td>\n",
       "      <td>8.740351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>him</td>\n",
       "      <td>7.261630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>surgery</td>\n",
       "      <td>2.921846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>man</td>\n",
       "      <td>1.739105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>outstanding</td>\n",
       "      <td>1.445992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>546</td>\n",
       "      <td>knee</td>\n",
       "      <td>1.440757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>staff</td>\n",
       "      <td>1.425463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>was</td>\n",
       "      <td>1.407302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>surgeon</td>\n",
       "      <td>1.263276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>pain</td>\n",
       "      <td>1.254968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>984</td>\n",
       "      <td>informative</td>\n",
       "      <td>1.242921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7301</td>\n",
       "      <td>yacoub</td>\n",
       "      <td>1.191698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>would</td>\n",
       "      <td>1.139274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>in</td>\n",
       "      <td>1.123240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1358</td>\n",
       "      <td>mother</td>\n",
       "      <td>1.070726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1111</td>\n",
       "      <td>arrogant</td>\n",
       "      <td>1.055663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>good</td>\n",
       "      <td>1.042893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>done</td>\n",
       "      <td>1.033809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>great</td>\n",
       "      <td>1.005547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1244</td>\n",
       "      <td>replacement</td>\n",
       "      <td>1.004791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327</td>\n",
       "      <td>called</td>\n",
       "      <td>0.983151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4753</td>\n",
       "      <td>faber</td>\n",
       "      <td>0.963013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>805</td>\n",
       "      <td>himself</td>\n",
       "      <td>0.962319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2791</td>\n",
       "      <td>cardiologist</td>\n",
       "      <td>0.926677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word     weight\n",
       "1               he  13.413569\n",
       "85             his   8.740351\n",
       "84             him   7.261630\n",
       "328        surgery   2.921846\n",
       "920            man   1.739105\n",
       "86     outstanding   1.445992\n",
       "546           knee   1.440757\n",
       "87           staff   1.425463\n",
       "13             was   1.407302\n",
       "222        surgeon   1.263276\n",
       "410           pain   1.254968\n",
       "984    informative   1.242921\n",
       "7301        yacoub   1.191698\n",
       "200          would   1.139274\n",
       "36              in   1.123240\n",
       "1358        mother   1.070726\n",
       "1111      arrogant   1.055663\n",
       "66            good   1.042893\n",
       "790           done   1.033809\n",
       "20           great   1.005547\n",
       "1244   replacement   1.004791\n",
       "327         called   0.983151\n",
       "4753         faber   0.963013\n",
       "805        himself   0.962319\n",
       "2791  cardiologist   0.926677"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weights.sort_values('weight', ascending=False)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>outstanding</td>\n",
       "      <td>1.445992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1111</td>\n",
       "      <td>arrogant</td>\n",
       "      <td>1.055663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>good</td>\n",
       "      <td>1.042893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>great</td>\n",
       "      <td>1.005547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4753</td>\n",
       "      <td>faber</td>\n",
       "      <td>0.963013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>944</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.926504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2291</td>\n",
       "      <td>kindness</td>\n",
       "      <td>0.791062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>561</td>\n",
       "      <td>efficient</td>\n",
       "      <td>0.757025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>er</td>\n",
       "      <td>0.663317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364</td>\n",
       "      <td>surgical</td>\n",
       "      <td>0.636397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1206</td>\n",
       "      <td>quick</td>\n",
       "      <td>0.621641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1243</td>\n",
       "      <td>total</td>\n",
       "      <td>0.617575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>courteous</td>\n",
       "      <td>0.616388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>much</td>\n",
       "      <td>0.612820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7156</td>\n",
       "      <td>udall</td>\n",
       "      <td>0.608856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>personal</td>\n",
       "      <td>0.605028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>892</td>\n",
       "      <td>leg</td>\n",
       "      <td>0.590397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7103</td>\n",
       "      <td>ubaldo</td>\n",
       "      <td>0.578983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>rare</td>\n",
       "      <td>0.575729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>782</td>\n",
       "      <td>terrible</td>\n",
       "      <td>0.574574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6911</td>\n",
       "      <td>rabady</td>\n",
       "      <td>0.571511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>556</td>\n",
       "      <td>full</td>\n",
       "      <td>0.535924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>678</td>\n",
       "      <td>respectful</td>\n",
       "      <td>0.534021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3254</td>\n",
       "      <td>rudest</td>\n",
       "      <td>0.528066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>tried</td>\n",
       "      <td>0.515483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word    weight\n",
       "86    outstanding  1.445992\n",
       "1111     arrogant  1.055663\n",
       "66           good  1.042893\n",
       "20          great  1.005547\n",
       "4753        faber  0.963013\n",
       "944      positive  0.926504\n",
       "2291     kindness  0.791062\n",
       "561     efficient  0.757025\n",
       "37             er  0.663317\n",
       "364      surgical  0.636397\n",
       "1206        quick  0.621641\n",
       "1243        total  0.617575\n",
       "249     courteous  0.616388\n",
       "110          much  0.612820\n",
       "7156        udall  0.608856\n",
       "875      personal  0.605028\n",
       "892           leg  0.590397\n",
       "7103       ubaldo  0.578983\n",
       "238          rare  0.575729\n",
       "782      terrible  0.574574\n",
       "6911       rabady  0.571511\n",
       "556          full  0.535924\n",
       "678    respectful  0.534021\n",
       "3254       rudest  0.528066\n",
       "286         tried  0.515483"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print only adjectives\n",
    "#male adjectives\n",
    "maleAdjectives = df_weights[df_weights['word'].isin(adjectives)].sort_values('weight', ascending=False)[:25]\n",
    "maleAdjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>she</td>\n",
       "      <td>-13.800402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>her</td>\n",
       "      <td>-11.209317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4699</td>\n",
       "      <td>ma</td>\n",
       "      <td>-3.015258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5981</td>\n",
       "      <td>kabbash</td>\n",
       "      <td>-1.778111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>588</td>\n",
       "      <td>woman</td>\n",
       "      <td>-1.689117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7309</td>\n",
       "      <td>yablonski</td>\n",
       "      <td>-1.351773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6774</td>\n",
       "      <td>qadir</td>\n",
       "      <td>-1.339115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7007</td>\n",
       "      <td>saadai</td>\n",
       "      <td>-1.300260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4072</td>\n",
       "      <td>amato</td>\n",
       "      <td>-1.271246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4442</td>\n",
       "      <td>eady</td>\n",
       "      <td>-1.269676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6708</td>\n",
       "      <td>pabolu</td>\n",
       "      <td>-1.206298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7319</td>\n",
       "      <td>yacoob</td>\n",
       "      <td>-1.158585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1031</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.131512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1452</td>\n",
       "      <td>sweet</td>\n",
       "      <td>-1.090542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2633</td>\n",
       "      <td>pediatrician</td>\n",
       "      <td>-1.071910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4004</td>\n",
       "      <td>alessio</td>\n",
       "      <td>-1.071878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>691</td>\n",
       "      <td>primary</td>\n",
       "      <td>-1.048746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>797</td>\n",
       "      <td>today</td>\n",
       "      <td>-1.030749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>766</td>\n",
       "      <td>given</td>\n",
       "      <td>-1.024516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6188</td>\n",
       "      <td>lafaver</td>\n",
       "      <td>-1.004139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>314</td>\n",
       "      <td>experience</td>\n",
       "      <td>-0.999158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>836</td>\n",
       "      <td>appointments</td>\n",
       "      <td>-0.991531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>prescription</td>\n",
       "      <td>-0.980985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1104</td>\n",
       "      <td>detailed</td>\n",
       "      <td>-0.968469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6504</td>\n",
       "      <td>nabors</td>\n",
       "      <td>-0.965723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word     weight\n",
       "43             she -13.800402\n",
       "396            her -11.209317\n",
       "4699            ma  -3.015258\n",
       "5981       kabbash  -1.778111\n",
       "588          woman  -1.689117\n",
       "7309     yablonski  -1.351773\n",
       "6774         qadir  -1.339115\n",
       "7007        saadai  -1.300260\n",
       "4072         amato  -1.271246\n",
       "4442          eady  -1.269676\n",
       "6708        pabolu  -1.206298\n",
       "7319        yacoob  -1.158585\n",
       "1031          test  -1.131512\n",
       "1452         sweet  -1.090542\n",
       "2633  pediatrician  -1.071910\n",
       "4004       alessio  -1.071878\n",
       "691        primary  -1.048746\n",
       "797          today  -1.030749\n",
       "766          given  -1.024516\n",
       "6188       lafaver  -1.004139\n",
       "314     experience  -0.999158\n",
       "836   appointments  -0.991531\n",
       "295   prescription  -0.980985\n",
       "1104      detailed  -0.968469\n",
       "6504        nabors  -0.965723"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weights.sort_values('weight', ascending=True)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4442</td>\n",
       "      <td>eady</td>\n",
       "      <td>-1.269676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1452</td>\n",
       "      <td>sweet</td>\n",
       "      <td>-1.090542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2633</td>\n",
       "      <td>pediatrician</td>\n",
       "      <td>-1.071910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>691</td>\n",
       "      <td>primary</td>\n",
       "      <td>-1.048746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>699</td>\n",
       "      <td>smart</td>\n",
       "      <td>-0.917067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>knowledgeable</td>\n",
       "      <td>-0.903161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303</td>\n",
       "      <td>unprofessional</td>\n",
       "      <td>-0.897514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3512</td>\n",
       "      <td>cabalona</td>\n",
       "      <td>-0.820959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>ok</td>\n",
       "      <td>-0.789854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>712</td>\n",
       "      <td>happy</td>\n",
       "      <td>-0.773196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>best</td>\n",
       "      <td>-0.771545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3128</td>\n",
       "      <td>insightful</td>\n",
       "      <td>-0.761697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2625</td>\n",
       "      <td>poor</td>\n",
       "      <td>-0.748159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>lowest</td>\n",
       "      <td>-0.739575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2965</td>\n",
       "      <td>lovely</td>\n",
       "      <td>-0.735815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2692</td>\n",
       "      <td>nasty</td>\n",
       "      <td>-0.726848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3125</td>\n",
       "      <td>angel</td>\n",
       "      <td>-0.684005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>high</td>\n",
       "      <td>-0.682567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4559</td>\n",
       "      <td>exellent</td>\n",
       "      <td>-0.680431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1533</td>\n",
       "      <td>perfect</td>\n",
       "      <td>-0.651384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3991</td>\n",
       "      <td>cancerous</td>\n",
       "      <td>-0.624872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>858</td>\n",
       "      <td>front</td>\n",
       "      <td>-0.619335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1314</td>\n",
       "      <td>annual</td>\n",
       "      <td>-0.582416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4944</td>\n",
       "      <td>cosmetic</td>\n",
       "      <td>-0.577782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1252</td>\n",
       "      <td>physical</td>\n",
       "      <td>-0.574494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word    weight\n",
       "4442            eady -1.269676\n",
       "1452           sweet -1.090542\n",
       "2633    pediatrician -1.071910\n",
       "691          primary -1.048746\n",
       "699            smart -0.917067\n",
       "14     knowledgeable -0.903161\n",
       "303   unprofessional -0.897514\n",
       "3512        cabalona -0.820959\n",
       "999               ok -0.789854\n",
       "712            happy -0.773196\n",
       "134             best -0.771545\n",
       "3128      insightful -0.761697\n",
       "2625            poor -0.748159\n",
       "2600          lowest -0.739575\n",
       "2965          lovely -0.735815\n",
       "2692           nasty -0.726848\n",
       "3125           angel -0.684005\n",
       "880             high -0.682567\n",
       "4559        exellent -0.680431\n",
       "1533         perfect -0.651384\n",
       "3991       cancerous -0.624872\n",
       "858            front -0.619335\n",
       "1314          annual -0.582416\n",
       "4944        cosmetic -0.577782\n",
       "1252        physical -0.574494"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#female adjectives\n",
    "femaleAdjectives = df_weights[df_weights['word'].isin(adjectives)].sort_values('weight', ascending=True)[:25]\n",
    "#maybe take out adjective specification\n",
    "#vocabulary being pruned down too aggressively\n",
    "femaleAdjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for most commonly found female adjectives:\n",
      "Agentic:  0\n",
      "Communal:  0\n",
      "Socio-communal:  0\n",
      "\n",
      "Results for most commonly found male adjectives:\n",
      "Agentic:  0\n",
      "Communal:  0\n",
      "Socio-communal:  0\n"
     ]
    }
   ],
   "source": [
    "#verify results\n",
    "agentic_terms = ['assertive','confident','aggressive','ambitious','dominan','forceful','independent','daring','outspoken','intellectua','earn','gain','know','insight','think']\n",
    "communal_terms = ['sympathetic','kind','help','affection','sensitive','nurtur','agreeab','tactful','interpersonal','warm','car','tactful']\n",
    "socio_communal = ['husband','wife','kid','babies','brother','child','colleague','family']\n",
    "\n",
    "print('Results for most commonly found female adjectives:')\n",
    "print('Agentic: ', femaleAdjectives['word'].isin(agentic_terms).sum())\n",
    "print('Communal: ', femaleAdjectives['word'].isin(communal_terms).sum())\n",
    "print('Socio-communal: ', femaleAdjectives['word'].isin(socio_communal).sum())\n",
    "print('')\n",
    "print('Results for most commonly found male adjectives:')\n",
    "print('Agentic: ', maleAdjectives['word'].isin(agentic_terms).sum())\n",
    "print('Communal: ', maleAdjectives['word'].isin(communal_terms).sum())\n",
    "print('Socio-communal: ', maleAdjectives['word'].isin(socio_communal).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can use medical reviews to run with recommnedation letter reviews to predict which is which, then throw out \n",
    "#heavily medical terms\n",
    "\n",
    "# recommendation system\n",
    "# maybe seek out positive words that don't distinguish between male and female\n",
    "# 4-class problem rather than two-class problem: take in star data and add pos/neg dimension to the data\n",
    "# word vector stuff from NLP class: use language models and figure out how often it appears in male context vs\n",
    "# female context. Ex: look at similarities between words: compare \"leadership\" to \"man/men\" \n",
    "\n",
    "#doubt raisers may not come out from this analysis: \"she may not be the best in her class...\"\n",
    "# subtle, hard to catch -> maybe the word \"not\"\n",
    "# append \"not\" to nearest adjective, negated adjectives might indicate doubt raisers\n",
    "# hedging terms to weaken a statement (weasel words): refusing to take a stand/hesitant\n",
    "# \"somewhat\", \"mostly\"\n",
    "\n",
    "# how to rephrase it: female-correlated to neutral, remove hedging terms\n",
    "# take an education based approach: \"this can be conveyed as ___. If that is not your intention, consider ___\"\n",
    "# crowdsourcing: emphasize anonymization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well does our healthgrades data predict the gender of our reference letter subjects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Letter</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>dear review committee members,\\r\\n\\r\\nit is wi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>this letter addresses some of my thoughts and ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I am writing this letter to recommend REDACTED...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>it is my sincere pleasure to nominate dr. REDA...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>i am writing to strongly recommend REDACTED RE...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>I am writing to highly recommend that you acce...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>i am writing to highly recommend that you acce...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>i am writing to highly recommend that you acce...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>\\r\\ni am writing to highly recommend that you ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>To the Graduate Program Admissions committee:\\...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Letter  Gender\n",
       "0   dear review committee members,\\r\\n\\r\\nit is wi...     0.0\n",
       "1   this letter addresses some of my thoughts and ...     0.0\n",
       "2   I am writing this letter to recommend REDACTED...     1.0\n",
       "4   it is my sincere pleasure to nominate dr. REDA...     0.0\n",
       "5   i am writing to strongly recommend REDACTED RE...     1.0\n",
       "..                                                ...     ...\n",
       "92  I am writing to highly recommend that you acce...     0.0\n",
       "93  i am writing to highly recommend that you acce...     0.0\n",
       "94  i am writing to highly recommend that you acce...     0.0\n",
       "95  \\r\\ni am writing to highly recommend that you ...     0.0\n",
       "96  To the Graduate Program Admissions committee:\\...     0.0\n",
       "\n",
       "[89 rows x 2 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters = pd.read_csv(\"./letters_tidied.csv\")\n",
    "letters.dropna(inplace = True)\n",
    "letters.columns = ['Letter', 'Gender']\n",
    "\n",
    "\n",
    "# testing data:\n",
    "letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Exelent he really care about you, he is very p...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Dr. A-Rahim was very knowledgeable about my lo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Horrible physician treats you like a kid. Pts ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dr Aaberg has been a very good dr for my husba...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Dr. Aaberg has been treating my macular degene...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8889</td>\n",
       "      <td>Very helpful and sincere about my pain needs! ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8890</td>\n",
       "      <td>Several of my children see Dr. Zach, she is a ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8891</td>\n",
       "      <td>Amazing Pediatric Neurologist stays up to date...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8892</td>\n",
       "      <td>Dr. Zach has been a Godsend for our daughter! ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8893</td>\n",
       "      <td>Very friendly doctor and not pushy. Makes you ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8894 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  Gender\n",
       "0     Exelent he really care about you, he is very p...     1.0\n",
       "1     Dr. A-Rahim was very knowledgeable about my lo...     1.0\n",
       "2     Horrible physician treats you like a kid. Pts ...     0.0\n",
       "3     Dr Aaberg has been a very good dr for my husba...     1.0\n",
       "4     Dr. Aaberg has been treating my macular degene...     1.0\n",
       "...                                                 ...     ...\n",
       "8889  Very helpful and sincere about my pain needs! ...     1.0\n",
       "8890  Several of my children see Dr. Zach, she is a ...     0.0\n",
       "8891  Amazing Pediatric Neurologist stays up to date...     0.0\n",
       "8892  Dr. Zach has been a Godsend for our daughter! ...     0.0\n",
       "8893  Very friendly doctor and not pushy. Makes you ...     0.0\n",
       "\n",
       "[8894 rows x 2 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data:\n",
    "\n",
    "reviewsByGender['Gender'] = reviewsByGender['Gender'].replace('Female', 0.0)\n",
    "reviewsByGender['Gender'] = reviewsByGender['Gender'].replace('Male', 1.0)\n",
    "reviewsByGender.dropna(inplace = True)\n",
    "reviewsByGender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = reviewsByGender['Review']\n",
    "y_train = reviewsByGender['Gender']\n",
    "x_new = letters['Letter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "vec = CountVectorizer(max_df=100, min_df=2, binary=False, strip_accents = None)\n",
    "X_train = vec.fit_transform(x_train)\n",
    "X_test = vec.transform(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.81        61\n",
      "           1       0.50      0.07      0.12        28\n",
      "\n",
      "    accuracy                           0.69        89\n",
      "   macro avg       0.60      0.52      0.47        89\n",
      "weighted avg       0.63      0.69      0.59        89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "gender_pred = nb.predict(X_test)\n",
    "print(classification_report(letters['Gender'], gender_pred, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6853932584269663\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(letters['Gender'], gender_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurensussman/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.13      0.22        61\n",
      "           1       0.31      0.86      0.46        28\n",
      "\n",
      "    accuracy                           0.36        89\n",
      "   macro avg       0.49      0.49      0.34        89\n",
      "weighted avg       0.55      0.36      0.29        89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=1e25, class_weight=\"balanced\")\n",
    "lr.fit(X_train, y_train)\n",
    "gender_pred = lr.predict(X_test)\n",
    "print(classification_report(letters['Gender'], gender_pred, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3595505617977528\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(letters['Gender'], gender_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This means: Logistic regression predicts accurate gender of letters at 46%\n",
    "### Naive Bayes predicts accurate gender at 69%\n",
    "\n",
    "Super small sample size though, so results are not definite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.46      0.58        61\n",
      "           1       0.38      0.71      0.49        28\n",
      "\n",
      "    accuracy                           0.54        89\n",
      "   macro avg       0.58      0.59      0.54        89\n",
      "weighted avg       0.65      0.54      0.55        89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train)\n",
    "gender_pred = knn.predict(X_test)\n",
    "print(classification_report(letters['Gender'], gender_pred, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5393258426966292\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(letters['Gender'], gender_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.48      0.60        61\n",
      "           1       0.40      0.75      0.52        28\n",
      "\n",
      "    accuracy                           0.56        89\n",
      "   macro avg       0.60      0.61      0.56        89\n",
      "weighted avg       0.68      0.56      0.57        89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "sv = svm.SVC(kernel='linear')\n",
    "sv.fit(X_train, y_train)\n",
    "gender_pred = sv.predict(X_test)\n",
    "print(classification_report(letters['Gender'], gender_pred, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5617977528089888\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(letters['Gender'], gender_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
